{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-Net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ireneraven/IDRiD/blob/master/U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qPvL-jH5oZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovr-XU6_9m6M",
        "colab_type": "text"
      },
      "source": [
        "# Nueva sección\n",
        "\n",
        "/content/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoHQXzb_8LGo",
        "colab_type": "text"
      },
      "source": [
        "# Modelo de U-Net para procesado masivo de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKwm3Ct_5u_u",
        "colab_type": "code",
        "outputId": "5d89c77d-25a7-4ec1-a2ae-c14096987b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Importar los módulos\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import image as mtpimg\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.compat.v1 import RunOptions\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Lambda\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from tensorflow.keras.layers  import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers  import MaxPooling2D, GlobalMaxPool2D\n",
        "from tensorflow.keras.layers  import concatenate, add\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiNHNwZT6Ezb",
        "colab_type": "text"
      },
      "source": [
        "Ahora a partir de los directorios vamos a coger las imágenes que tenemos de train y sus correspondientes máscaras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMAtTQqo6CqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(path, path2):\n",
        "    \n",
        "    #otra manera sería: filesInPathTrain = next(os.walk(myPath))[2] - Estaría ya ordenado\n",
        "    \n",
        "    filesInPathTrain = os.listdir(path)\n",
        "    filesInPathTrain.sort(key = len)\n",
        "    imagesTrain = np.zeros((len(filesInPathTrain), 2848, 4288, 3), dtype=np.float32)\n",
        "    \n",
        "    filesInPathMask = os.listdir(path2)\n",
        "    filesInPathMask.sort(key = len)\n",
        "    imagesMask = np.zeros((len(filesInPathMask), 2848, 4288, 3), dtype=np.float32)\n",
        "    \n",
        "\n",
        "    for i, filename in tqdm(enumerate(filesInPathTrain)):\n",
        "        imageToRead = path + r'\\\\' + str(filename)\n",
        "        img = img_to_array(mtpimg.imread(imageToRead))/255.0\n",
        "        if img is not None:\n",
        "            imagesTrain[i] = img\n",
        "        \n",
        "\n",
        "        imageToRead2 = path2 + r'\\\\' + str(filesInPathMask[i])\n",
        "        img2 = img_to_array(io.imread(imageToRead2))/255.0\n",
        "        if img2 is not None:\n",
        "            imagesMask[i] = img2\n",
        "        \n",
        "\n",
        "\n",
        "    return imagesTrain, imagesMask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlmBIvZ16VbS",
        "colab_type": "text"
      },
      "source": [
        "Definimos la U-Net\n",
        "![texto alternativo](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMpq3A0N6gH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) Since each block consicts on two convolutions:\n",
        "\n",
        "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
        "    # first layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    # second layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(x)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "# 2) We create a function to define the UNET Model\n",
        "def get_unet(inputs, n_filters=16, dropout=0.5, batchnorm=True):\n",
        "    # contracting path\n",
        "    c1 = conv2d_block(inputs, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "    p1 = Dropout(dropout*0.5)(p1)\n",
        "\n",
        "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "\n",
        "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "\n",
        "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "    \n",
        "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    # expansive path\n",
        "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    outputs = Conv2D(3, (1, 1), activation='sigmoid')(c9)\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsUrQ8A47CVt",
        "colab_type": "text"
      },
      "source": [
        "El código que nos ha dicho JL. que puede resolver el problema (a mi no me iba)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aprx-FaB7LBK",
        "colab_type": "code",
        "outputId": "eb2f177c-9352-4013-c41a-2121ad64fc01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Specifying the input shape\n",
        "input_shape = Input((2848, 4288, 3), dtype = 'float32')\n",
        "\n",
        "#For the OOM error\n",
        "run_opts = RunOptions(report_tensor_allocations_upon_oom = True)\n",
        "\n",
        "model = get_unet(input_shape, n_filters=16, dropout=0.1, batchnorm=True)\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])#, options = run_opts)\n",
        "model.summary()\n",
        "#Cuando sean más cambiar a categorical_crossentropy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 2848, 4288,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 2848, 4288, 1 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2848, 4288, 1 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 2848, 4288, 1 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 2848, 4288, 1 2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 2848, 4288, 1 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 2848, 4288, 1 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 1424, 2144, 1 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1424, 2144, 1 0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 1424, 2144, 3 4640        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 1424, 2144, 3 128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1424, 2144, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 1424, 2144, 3 9248        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1424, 2144, 3 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1424, 2144, 3 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 712, 1072, 32 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 712, 1072, 32 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 712, 1072, 64 18496       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 712, 1072, 64 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 712, 1072, 64 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 712, 1072, 64 36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 712, 1072, 64 256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 712, 1072, 64 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 356, 536, 64) 0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 356, 536, 64) 0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 356, 536, 128 73856       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 356, 536, 128 512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 356, 536, 128 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 356, 536, 128 147584      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 356, 536, 128 512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 356, 536, 128 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 178, 268, 128 0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 178, 268, 128 0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 178, 268, 256 295168      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 178, 268, 256 1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 178, 268, 256 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 178, 268, 256 590080      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 178, 268, 256 1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 178, 268, 256 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 356, 536, 128 295040      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 356, 536, 256 0           conv2d_transpose[0][0]           \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 356, 536, 256 0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 356, 536, 128 295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 356, 536, 128 512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 356, 536, 128 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 356, 536, 128 147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 356, 536, 128 512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 356, 536, 128 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 712, 1072, 64 73792       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 712, 1072, 12 0           conv2d_transpose_1[0][0]         \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 712, 1072, 12 0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 712, 1072, 64 73792       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 712, 1072, 64 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 712, 1072, 64 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 712, 1072, 64 36928       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 712, 1072, 64 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 712, 1072, 64 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 1424, 2144, 3 18464       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1424, 2144, 6 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 1424, 2144, 6 0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 1424, 2144, 3 18464       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 1424, 2144, 3 128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 1424, 2144, 3 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 1424, 2144, 3 9248        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 1424, 2144, 3 128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 1424, 2144, 3 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 2848, 4288, 1 4624        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 2848, 4288, 3 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 2848, 4288, 3 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 2848, 4288, 1 4624        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 2848, 4288, 1 64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 2848, 4288, 1 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 2848, 4288, 1 2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 2848, 4288, 1 64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 2848, 4288, 1 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 2848, 4288, 3 51          activation_17[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,164,627\n",
            "Trainable params: 2,161,683\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA9maBaF7beC",
        "colab_type": "text"
      },
      "source": [
        "Ahora usamos la función para coger los datos y luego dividir las imágenes y sus máscaras en train y valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "314UncR97jcy",
        "colab_type": "code",
        "outputId": "3bc5a5b0-c957-4792-b9ed-683bad8437be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "myPath = r\"C:\\\\Users\\\\pablo\\\\Documents\\\\2_PABLO\\\\2. Universidad\\\\(4) Cuarto año\\\\2_Segundo semestre\\\\Procesado masivo de datos\\\\Programación\\\\Fotos\\\\A. Segmentation\\\\1. Original Images\\\\a. Training Set\"\n",
        "myMaskPath = r\"C:\\\\Users\\\\pablo\\\\Documents\\\\2_PABLO\\\\2. Universidad\\\\(4) Cuarto año\\\\2_Segundo semestre\\\\Procesado masivo de datos\\\\Programación\\\\Fotos\\\\A. Segmentation\\\\2. All Segmentation Groundtruths\\\\a. Training Set\\5. Optic Disc\"\n",
        "\n",
        "X, y = get_data(myPath, myMaskPath)\n",
        "\n",
        "#Dividir en X_train, X_valid, y_train, y_valid\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=2018)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-109334c8e691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmyMaskPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"C:\\\\Users\\\\pablo\\\\Documents\\\\2_PABLO\\\\2. Universidad\\\\(4) Cuarto año\\\\2_Segundo semestre\\\\Procesado masivo de datos\\\\Programación\\\\Fotos\\\\A. Segmentation\\\\2. All Segmentation Groundtruths\\\\a. Training Set\\5. Optic Disc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Dividir en X_train, X_valid, y_train, y_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-f32ffd066351>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(path, path2)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#otra manera sería: filesInPathTrain = next(os.walk(myPath))[2] - Estaría ya ordenado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfilesInPathTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfilesInPathTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimagesTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilesInPathTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2848\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4288\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\pablo\\\\\\\\Documents\\\\\\\\2_PABLO\\\\\\\\2. Universidad\\\\\\\\(4) Cuarto año\\\\\\\\2_Segundo semestre\\\\\\\\Procesado masivo de datos\\\\\\\\Programación\\\\\\\\Fotos\\\\\\\\A. Segmentation\\\\\\\\1. Original Images\\\\\\\\a. Training Set'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: Current TensorFlow version is 2.2.0-rc2. To use TF 1.x instead,\nrestart your runtime (Ctrl+M .) and run \"%tensorflow_version 1.x\" before\nyou run \"import tensorflow\".\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAt8Pjvp7tg5",
        "colab_type": "text"
      },
      "source": [
        "Ahora ponemos el modelo a entrenarse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DblDty_W7zmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Estas son las callbacks, las definimos para que no se produzca overfitting y underfitting y además se guarde mi modelo.\n",
        "modelCallbacks = [\n",
        "    EarlyStopping(monitor = 'val_loss', patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(monitor = 'val_loss', factor=0.2, patience=3, min_lr=0.00001, verbose=1),\n",
        "    ModelCheckpoint('model-opticDisc.h5', verbose=1, save_best_only=True, save_weights_only=True),\n",
        "    TensorBoard(log_dir = 'logs')\n",
        "    ]\n",
        "\n",
        "#Esta línea antes daba error\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "results = model.fit(X_train, y_train, batch_size=None, epochs=100, verbose = 2, callbacks=modelCallbacks, validation_data=(X_valid, y_valid))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}